{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac3ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell made executed if you need install the extern packages.\n",
    "# all the others packages are included in the Anaconda \n",
    "!pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ff91a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# this package is extern from Jupyter Notebook\n",
    "# it is used to create maps. It's so cool. Try it!\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e020468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this CELL I test if all files are in the correct directory\n",
    "try:\n",
    "    list_tripFiles = ['dataFiles/data-sample_data-nyctaxi-trips-2009-json_corrigido.json',\n",
    "                      'dataFiles/data-sample_data-nyctaxi-trips-2010-json_corrigido.json',\n",
    "                      'dataFiles/data-sample_data-nyctaxi-trips-2011-json_corrigido.json',\n",
    "                      'dataFiles/data-sample_data-nyctaxi-trips-2012-json_corrigido.json']\n",
    "    \n",
    "    for file in list_tripFiles:\n",
    "        os.path.isfile(file)\n",
    "        \n",
    "    vendorsFile = 'dataFiles/data-vendor_lookup-csv.csv'\n",
    "    dfDataVendors = pd.read_csv(vendorsFile)\n",
    "    \n",
    "    # this file contain the all types of payment\n",
    "    # I don't understand why uses it, but I open it. Maybe in future...\n",
    "    paymentModes = 'dataFiles/data-payment_lookup-csv.csv'\n",
    "    dfPaymentModes = pd.read_csv(paymentModes)\n",
    "        \n",
    "except:\n",
    "    print(\"Não foi possível abrir algum dos arquivos. Verifique se TODOS estão na pasta correta ['/dataFiles']!\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aece8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the first function.\n",
    "# it will receive one list with the '.json' files names, open each one and append all them in a big Pandas DataFrame\n",
    "\n",
    "def createBigDF(list_files):\n",
    "    \n",
    "    # the big DataFrame\n",
    "    dfAllFiles = pd.DataFrame()\n",
    "    \n",
    "    for file in list_files:\n",
    "        dfOneFile = pd.read_json(file)\n",
    "        dfAllFiles = dfAllFiles.append(dfOneFile, ignore_index=True)\n",
    "        \n",
    "    return dfAllFiles\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff42baee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function answers the first question: \n",
    "    # Qual a distância média percorrida por viagens com no máximo 2 passageiros.\n",
    "    \n",
    "\n",
    "def meanDistance(list_DataTrips):\n",
    "    \n",
    "    # call the function \"createBigDF\" to get one DataFrame with all json files\n",
    "    dfDataTrips = createBigDF(list_DataTrips)   \n",
    "    \n",
    "    # create a new DataFrame with a filter in 'passenger_count' column\n",
    "    dfPassengers = dfDataTrips.query('passenger_count <= 2')\n",
    "    \n",
    "    # get the mean of travelled distance. Using the filter above and all trips \n",
    "    dfMeanTotal = np.mean(dfDataTrips['trip_distance'])\n",
    "    dfMeanPass = np.mean(dfPassengers['trip_distance'])\n",
    "    \n",
    "    dfMeanTotal = round(dfMeanTotal, 2)\n",
    "    dfMeanPass = round(dfMeanPass, 2)\n",
    "    \n",
    "    # here start the chart\n",
    "    # create two arrays with numpy function (with and without filter)\n",
    "    x = np.array([\"Qualquer Nº de Passageiros\", \"2 ou menos Passageiros\"])\n",
    "    y = np.array([dfMeanTotal, dfMeanPass])\n",
    "    \n",
    "    # passing datas to plt function make the chart\n",
    "    plt.xlabel(\"Número de Passageiros\")\n",
    "    plt.ylabel(\"Distância Média da Corrida\")\n",
    "    \n",
    "    # this two line bellow add a description in the top of each bar.\n",
    "    # is not the best way to make this, because exist the method bar_label for this, \n",
    "    # but it only exists in 3.4 version from Matplotlib and younger.\n",
    "    # I updated my Anaconda environment and the MatPlotLib, but it not received this version. I don't know why.\n",
    "    plt.annotate(y[0], (-0.05, y[0])) \n",
    "    plt.annotate(y[1], (0.95, y[1]))\n",
    "    \n",
    "    plt.bar(x, y, color='blue', alpha=0.75, width=0.5)   \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504135fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call function to answear the question 1.\n",
    "meanDistance(list_tripFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96174c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the second function. It try answear the second question...\n",
    "    # Quais os 3 maiores vendors em quantidade total de dinheiro arrecadado.\n",
    "    \n",
    "# this question can have three answears. \n",
    "    #1 Count only Cash payment\n",
    "    #2 Count only fares and surcharges (without tips and tolls)\n",
    "    #3 Count the total amount\n",
    "# here I will uses the second and third counts way\n",
    "\n",
    "def bigVendors(dfVendors, list_DataTrips):\n",
    "    \n",
    "    # get DataFrame from json Files\n",
    "    dfTrips = createBigDF(list_DataTrips)\n",
    "    \n",
    "    # get the quantity of Vendors in file 'data-vendor_lookup-csv.csv' (received in the function parameter)\n",
    "    total_vendors = len(dfVendors)\n",
    "    \n",
    "    # create a empty DataFrame to add datas of search\n",
    "    df_big_vendors = pd.DataFrame()\n",
    "    df_big_vendors['Alias'] = dfVendors['vendor_id']\n",
    "    df_big_vendors['Name'] = dfVendors['name']\n",
    "    \n",
    "    # create two empty list to add amount of each search in loop\n",
    "    list_amount = []\n",
    "    list_fare_amount = []\n",
    "    \n",
    "    i = 0\n",
    "    while i < total_vendors:\n",
    "        \n",
    "        # get vendor_id and uses it to filter only trips of the respective vendor\n",
    "        vendor = dfVendors[\"vendor_id\"][i]\n",
    "        dfVendor = dfTrips.query(f'vendor_id == \"{vendor}\"')\n",
    "        \n",
    "        # so, sum the amount of all trips, in the two ways mentioned above\n",
    "        dfSumVendor = np.sum(dfVendor['total_amount']).round(2)\n",
    "        list_amount.append(int(dfSumVendor))\n",
    "        \n",
    "        dfSumFares = np.sum(dfVendor['fare_amount'] + dfVendor['surcharge']).round(2)\n",
    "        list_fare_amount.append(int(dfSumFares))\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    # add sums lists in DataFrame, each in different column    \n",
    "    df_big_vendors['Amount'] = list_amount\n",
    "    df_big_vendors['Fare_Amount'] = list_fare_amount\n",
    "    \n",
    "    df_big_vendors = df_big_vendors.nlargest(3, 'Amount') # get only three biggest vendors\n",
    "    \n",
    "    x = np.arange(len(df_big_vendors['Name']))  # the label locations\n",
    "    width = 0.35  # the width of the bars\n",
    "    \n",
    "    # create the group bars chart\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(x - width/2, df_big_vendors['Amount'], width, label='Faturamento Total')\n",
    "    rects2 = ax.bar(x + width/2, df_big_vendors['Fare_Amount'], width, label='Somente Tarifas')\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels\n",
    "    ax.set_ylabel('Faturamento')\n",
    "    ax.set_title('Maiores Companhias em Faturamento')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(df_big_vendors['Name'])\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.xticks(rotation=30)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7377dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function above\n",
    "bigVendors(dfDataVendors, list_tripFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dba5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the function to answear the following question:\n",
    "    # Faça um histograma da distribuição mensal, nos 4 anos, de corridas pagas em dinheiro.\n",
    "\n",
    "def histogramCash(list_DataTrips):\n",
    "    \n",
    "    # get the complete DataFrame and convert the column with string datetime datas to datetime\n",
    "    dfDataTrips = createBigDF(list_DataTrips)   \n",
    "    dfDataTrips['pickup_datetime'] = pd.to_datetime(dfDataTrips['pickup_datetime'])\n",
    "    \n",
    "    # filter to get only CASH payment type \n",
    "    dfCashTrips = dfDataTrips.query('payment_type == \"CASH\" | payment_type == \"Cash\"')\n",
    "    \n",
    "    # Create a empty DataFrame and list\n",
    "    df_count_cash_trips = pd.DataFrame()\n",
    "    list_count_trips = []\n",
    "    \n",
    "    # I create a variable month to iterate in while loop\n",
    "    # I made this to separate all datas in months, to show in histogram chart\n",
    "    month = 1\n",
    "    while month <= 12:\n",
    "        \n",
    "        # filter only of iterate month and count trips, so add in list\n",
    "        trips = dfCashTrips.query('pickup_datetime.dt.month == @month')\n",
    "        count_trips = np.count_nonzero(trips['pickup_datetime'])\n",
    "        list_count_trips.append(count_trips)\n",
    "        month += 1\n",
    "    \n",
    "    # add the list in DataFrame\n",
    "    df_count_cash_trips['Total_trips'] = list_count_trips\n",
    "\n",
    "    # create datas to chart\n",
    "    y = np.array(df_count_cash_trips['Total_trips'])\n",
    "\n",
    "    plt.ylabel(\"Quantidade de Meses\")\n",
    "    plt.xlabel(\"Total Recebido em Dinheiro\")\n",
    "    plt.title('Histograma de Faturamento Mensal')\n",
    "    plt.hist(y, 20, facecolor='g', alpha=0.75)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b8d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call function to make a histogram\n",
    "histogramCash(list_tripFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba6ee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the fourth function. For me, the most difficult\n",
    "# it will answear the following question:\n",
    "    # Faça um gráfico de série temporal contando a quantidade de gorjetas de cada dia, nos últimos 3 meses de 2012.\n",
    "def timeSeries(dfDataTrips2012):\n",
    "    \n",
    "    # get only file from 2012 year and convert column to datetime format\n",
    "    dfDataTrips2012['pickup_datetime'] = pd.to_datetime(dfDataTrips2012['pickup_datetime'])\n",
    "    \n",
    "    # get datas from months Oct, Nov and Dec (bigger than 9), and where exist tips\n",
    "    df_tips = dfDataTrips2012.query(\"pickup_datetime.dt.month > 9 & tip_amount > 0\")\n",
    "\n",
    "    month = 10 # control variable of each month\n",
    "    dict_diary_tips = {}\n",
    "    list_days = []\n",
    "    list_tips = []\n",
    "    # this loop will iterate three times, in three last months of 2012\n",
    "    while month <= 12:\n",
    "        \n",
    "        day = 1\n",
    "        # this internal loop will iterate in each day\n",
    "        while day <= 31:\n",
    "            list_days.append((str(month)+\"-\"+str(day)))\n",
    "            \n",
    "            # November don't have 31 days, so, add '0' in the list\n",
    "            if month == 11 and day == 31:\n",
    "                list_tips.append(0)\n",
    "            else:\n",
    "                # count the amount of tips in the respective day\n",
    "                diary_tips = df_tips.query(f\"pickup_datetime.dt.month == {month} & pickup_datetime.dt.day == {day}\")\n",
    "                list_tips.append(len(diary_tips.index))\n",
    "\n",
    "            day += 1\n",
    "        # I decided add the lists in a dictionary because is easier add new elemments\n",
    "        # so add in the next pass the dictionary in the DataFrame\n",
    "        dict_diary_tips[\"Dias\"] = list_days\n",
    "        dict_diary_tips[\"Gorgetas\"] = list_tips\n",
    "        month += 1\n",
    "\n",
    "    df_diary_tips = pd.DataFrame(dict_diary_tips)\n",
    "\n",
    "    # start format the DataFrame to create a chart\n",
    "    df_diary_tips = df_diary_tips.set_index('Dias')\n",
    "    df_diary_tips.plot()\n",
    "    \n",
    "    # define the time series chart form\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # get the decompose of DataFrame, and add each one in a different variable  \n",
    "    resultado = seasonal_decompose(df_diary_tips[\"Gorgetas\"], period=12, extrapolate_trend='freq')\n",
    "    tendencia = resultado.trend\n",
    "    sazonalidade = resultado.seasonal\n",
    "    residuo = resultado.resid\n",
    "    \n",
    "    # all the four charts are very similar, so decided put them in a for loop\n",
    "    list_seasonal =[['Série Temporal', 'b'],['Tendência', 'r'], ['Sazonalidade', 'y'], ['Resíduo', 'g']]\n",
    "    \n",
    "    s = 0\n",
    "    for seasonal in list_seasonal:\n",
    "    \n",
    "        plt.xlabel('Meses-Dias')\n",
    "        plt.xticks([])\n",
    "        plt.ylabel('Quantidade de Gorgetas')\n",
    "        plt.title(seasonal[0])\n",
    "        \n",
    "        if s == 0:\n",
    "            plt.show()\n",
    "        elif s == 1:\n",
    "            plt.plot(tendencia, color=seasonal[1])\n",
    "        elif s == 2:\n",
    "            plt.plot(sazonalidade, color=seasonal[1])\n",
    "        else:\n",
    "            plt.plot(resíduo, color=seasonal[1])\n",
    "        \n",
    "        plt.show()\n",
    "        s += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf1b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get json file from 2012 year and call the function\n",
    "dfDataTrips12 = pd.read_json(list_tripFiles[3])\n",
    "timeSeries(dfDataTrips12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008efeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the fifth function, that will answear the following question:\n",
    "    # Qual o tempo médio das corridas nos dias de sábado e domingo;\n",
    "\n",
    "def timeRunsWeekend(list_DataTrips):\n",
    "    \n",
    "    dfDataTrips = createBigDF(list_DataTrips)\n",
    "    \n",
    "    # convert the two columns with dates to correct datetime format\n",
    "    dfDataTrips['pickup_datetime'] = pd.to_datetime(dfDataTrips['pickup_datetime'])\n",
    "    dfDataTrips['dropoff_datetime'] = pd.to_datetime(dfDataTrips['dropoff_datetime'])\n",
    "    \n",
    "    # create three DataFrames, to separate trips from work days, saturdays and sundays\n",
    "    dfSundayTrips = dfDataTrips.query(\"pickup_datetime.dt.dayofweek == 6\")\n",
    "    dfSaturdayTrips = dfDataTrips.query(\"pickup_datetime.dt.dayofweek == 5\")\n",
    "    dfWorkdayTrips = dfDataTrips.query(\"pickup_datetime.dt.dayofweek <= 4\")\n",
    "    \n",
    "    # create a dictionary to add only the mean of time trip from each dataframe above\n",
    "    # for this, I uses the mean method from numpy package\n",
    "    dict_timeTrips = {}\n",
    "    dict_timeTrips['work_time_trip'] = np.mean(dfWorkdayTrips['dropoff_datetime'] - dfWorkdayTrips['pickup_datetime'])\n",
    "    dict_timeTrips['sat_time_trip'] = np.mean(dfSaturdayTrips['dropoff_datetime'] - dfSaturdayTrips['pickup_datetime'])\n",
    "    dict_timeTrips['sun_time_trip'] = np.mean(dfSundayTrips['dropoff_datetime'] - dfSundayTrips['pickup_datetime'])\n",
    "    \n",
    "        '''\n",
    "        df_weekend_times = pd.DataFrame()\n",
    "        df_weekend_times['pickup'] = dfWeekendTrips['pickup_datetime']\n",
    "        df_weekend_times['dropoff'] = dfWeekendTrips['dropoff_datetime']\n",
    "        df_weekend_times['time_trip'] = df_weekend_times['dropoff'] - df_weekend_times['pickup']\n",
    "\n",
    "        df_week_times = pd.DataFrame()\n",
    "        df_week_times['pickup'] = dfWeekTrips['pickup_datetime']\n",
    "        df_week_times['dropoff'] = dfWeekTrips['dropoff_datetime']\n",
    "        df_week_times['time_trip'] = df_week_times['dropoff'] - df_week_times['pickup']\n",
    "\n",
    "        meanWeekend = np.mean(df_weekend_times['time_trip'])\n",
    "        meanWeek = np.mean(df_week_times['time_trip'])\n",
    "        '''\n",
    "    # the return of numpy mean is a timedelta format. It's complicate work with this.\n",
    "    # so, I convert to string and then I convert to float\n",
    "    str_meanWork = str(dfTimeTrips['work_time_trip'])    \n",
    "    str_meanSat = str(dfTimeTrips['sat_time_trip'])\n",
    "    str_meanSun = str(dfTimeTrips['sun_time_trip'])\n",
    "    \n",
    "    cut_meanWork = float(str_meanWork[10:12] + '.' + str_meanWor[13:15])\n",
    "    cut_meanSat = float(str_meanSat[10:12] + '.' + str_meanSat[13:15])\n",
    "    cut_meanSun = float(str_meanSun[10:12] + '.' + str_meanSun[13:15])\n",
    "    \n",
    "    # create arrays to axis of chart    \n",
    "    x = np.array([\"Dias Úteis\", \"Sábados\", \"Domingos\"])\n",
    "    y = np.array([cut_meanWork, cut_meanSat, cut_meanSun])   \n",
    "    \n",
    "    # create more one bealtiful chart\n",
    "    plt.xlabel(\"Separação de Dias\")\n",
    "    plt.ylabel(\"Tempo Médio da Corrida (Minutos)\")\n",
    "    plt.annotate(y[0], (-0.05, y[0]))\n",
    "    plt.annotate(y[1], (0.95, y[1]))v\n",
    "    plt.annotate(y[2], (1.95, y[2]))\n",
    "    plt.bar(x, y, width=0.5)\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd7778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function above\n",
    "timeRunsWeekend(list_tripFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab1567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here the code stop to uses separated functions\n",
    "# It get the json trips file of 2010 year and add a dataframe, again\n",
    "dfDataTrips10 = pd.read_json(list_tripFiles[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa39ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is coolest function (I guess) from my code.\n",
    "\n",
    "# first, create a map from ny city, with zoom start 11. A view almost complete from city\n",
    "map_ny = folium.Map(location=[40.74295,-74.004114],zoom_start=11)\n",
    "\n",
    "# this is a loop to add markers from trips, pickups and dropoff\n",
    "# I don't send all dataFrame because my PC can't handle this quantity of datas\n",
    "i = 0\n",
    "while i <= 10000:\n",
    "    \n",
    "    # first, get all latitudes and longitudes from pickups and dropoff and add separate variable\n",
    "    lat_in = dfDataTrips10.loc[i]['pickup_latitude']\n",
    "    lat_out = dfDataTrips10.loc[i]['dropoff_latitude']\n",
    "    long_in = dfDataTrips10.loc[i]['pickup_longitude']\n",
    "    long_out = dfDataTrips10.loc[i]['dropoff_longitude']\n",
    "    \n",
    "    # add marker from pickup\n",
    "    folium.Marker(\n",
    "            [lat_in,long_in],\n",
    "            popup='<i>Pickup Place</i>', \n",
    "            tooltip=i,\n",
    "            icon=folium.Icon(color='red')\n",
    "            ).add_to(map_ny)\n",
    "    \n",
    "    # add marker from dropoff\n",
    "    folium.Marker(\n",
    "            [lat_out,long_out],\n",
    "            popup='<i>DropOff Place</i>', \n",
    "            tooltip=i,\n",
    "            icon=folium.Icon(color='green')\n",
    "            ).add_to(map_ny)\n",
    "    i += 1\n",
    "\n",
    "map_ny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04775d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
